{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, seq_len, n_features, embedding_dim=64):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.seq_len, self.n_features = seq_len, n_features\n",
    "        self.embedding_dim, self.hidden_dim = embedding_dim, 2 * embedding_dim\n",
    "        \n",
    "        self.rnn1 = nn.LSTM(\n",
    "            input_size=n_features,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.rnn2 = nn.LSTM(\n",
    "            input_size=self.hidden_dim,\n",
    "            hidden_size=embedding_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        # # x = x.reshape((1, self.seq_len, self.n_features))\n",
    "        \n",
    "        print(x.shape)\n",
    "        x, (hidden_n, cell_n) = self.rnn1(x)\n",
    "        print(x.shape)\n",
    "        x, (hidden_n, cell_n) = self.rnn2(x)\n",
    "        print(x.shape)\n",
    "        print(hidden_n.shape)\n",
    "        \n",
    "        return hidden_n\n",
    "        # return hidden_n.reshape((self.n_features, self.embedding_dim))\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, seq_len, input_dim=64, n_features=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.seq_len, self.input_dim = seq_len, input_dim\n",
    "        self.hidden_dim, self.n_features = 2 * input_dim, n_features\n",
    "        \n",
    "        self.rnn1 = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=input_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.rnn2 = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.output_layer = nn.Linear(self.hidden_dim, n_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.repeat(self.seq_len, self.n_features)\n",
    "        x = x.reshape((self.n_features, self.seq_len, self.input_dim))\n",
    "        \n",
    "        x, (hidden_n, cell_n) = self.rnn1(x)\n",
    "        x, (hidden_n, cell_n) = self.rnn2(x)\n",
    "        \n",
    "        x = x.reshape((self.seq_len, self.hidden_dim))\n",
    "\n",
    "        return self.output_layer(x)\n",
    "\n",
    "class RecurrentAutoencoder(nn.Module):\n",
    "    def __init__(self, seq_len, n_features, embedding_dim=64):\n",
    "        super(RecurrentAutoencoder, self).__init__()\n",
    "    \n",
    "        self.encoder = Encoder(seq_len, n_features, embedding_dim).to(device)\n",
    "        self.decoder = Decoder(seq_len, embedding_dim, n_features).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        print(x.shape)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_kaggle(metadata_filepath, sample_freq, N_start=0, N_end=10, only_health=False):\n",
    "    \"\"\"Загрузка данных из файлов.\\n\n",
    "    Работает только при наличии директории 'records',\\n\n",
    "    в которой пять папок по 5000 файлов записей\"\"\"\n",
    "    \n",
    "    # Загружаем метаданные и выбираем срезом нужные\n",
    "    metadata_full = pd.read_csv('/kaggle/input/metadata/metadata.csv')\n",
    "    metadata = metadata_full.iloc[N_start:N_end]\n",
    "\n",
    "    # Убираем лишние столбцы, приводим к типу int32\n",
    "    metadata = metadata.drop(columns=['Date', 'Patient_ID'])\n",
    "    metadata['Age'].astype(np.int32)\n",
    "    metadata['N'].astype(np.int32)\n",
    "\n",
    "\n",
    "    if only_health:\n",
    "        # Берём только здоровых людей\n",
    "        health_metadata = metadata.loc[metadata['AHA_Code'] == '1']\n",
    "        id_metadata = health_metadata['ECG_ID'].values\n",
    "        labels = health_metadata['AHA_Code'].values\n",
    "    else:\n",
    "        # Берём всех\n",
    "        id_metadata = metadata['ECG_ID'].values\n",
    "        labels = metadata['AHA_Code'].values\n",
    "\n",
    "    signals = []\n",
    "\n",
    "    for i in id_metadata:\n",
    "        # Из Axxxxx оставляем численную часть\n",
    "        number = int(i[1:])\n",
    "     \n",
    "        # Считываем файл.\n",
    "        with h5py.File(f'/kaggle/input/ecgdata/records/{i}.h5', 'r') as f:\n",
    "            signals.append(f['ecg'][()])\n",
    "    \n",
    "    health_n = len(labels[labels == '1'])\n",
    "    diseased_n = len(labels[labels != '1'])\n",
    "\n",
    "    print(f\"Data loaded successfully.\\n\\\n",
    "          Health    number:     {health_n}\\n\\\n",
    "          Diseased  number:     {diseased_n}\\n\\n\")\n",
    "    return signals, labels\n",
    "\n",
    "def load_data(metadata_filepath, sample_freq, N_start=0, N_end=10, only_health=False):\n",
    "    \"\"\"Загрузка данных из файлов.\\n\n",
    "    Работает только при наличии директории 'records',\\n\n",
    "    в которой пять папок по 5000 файлов записей\"\"\"\n",
    "    \n",
    "    # Загружаем метаданные и выбираем срезом нужные\n",
    "    metadata_full = pd.read_csv('metadata.csv')\n",
    "    metadata = metadata_full.iloc[N_start:N_end]\n",
    "\n",
    "    # Убираем лишние столбцы, приводим к типу int32\n",
    "    metadata = metadata.drop(columns=['Date', 'Patient_ID'])\n",
    "    metadata['Age'].astype(np.int32)\n",
    "    metadata['N'].astype(np.int32)\n",
    "\n",
    "\n",
    "    if only_health:\n",
    "        # Берём только здоровых людей\n",
    "        health_metadata = metadata.loc[metadata['AHA_Code'] == '1']\n",
    "        id_metadata = health_metadata['ECG_ID'].values\n",
    "        labels = health_metadata['AHA_Code'].values\n",
    "    else:\n",
    "        # Берём всех\n",
    "        id_metadata = metadata['ECG_ID'].values\n",
    "        labels = metadata['AHA_Code'].values\n",
    "\n",
    "    signals = []\n",
    "\n",
    "    for i in id_metadata:\n",
    "        # Из Axxxxx оставляем численную часть\n",
    "        number = int(i[1:])\n",
    "\n",
    "        # В каждой папке 5000 файлов (кроме пятой), поэтому,\n",
    "        # чтобы узнать номер папки, в которой запись, делим на 5000\n",
    "        record_num = (number - 1) // 5000\n",
    "        if record_num > 4:\n",
    "            record_num = 4\n",
    "        record_num = record_num + 1\n",
    "        \n",
    "        # Считываем файл.\n",
    "        with h5py.File(f'records/record{record_num}/{i}.h5', 'r') as f:\n",
    "            signals.append(f['ecg'][()])\n",
    "    \n",
    "    health_n = len(labels[labels == '1'])\n",
    "    diseased_n = len(labels[labels != '1'])\n",
    "\n",
    "    print(f\"Data loaded successfully.\\n\\\n",
    "          Health    number:     {health_n}\\n\\\n",
    "          Diseased  number:     {diseased_n}\\n\\n\")\n",
    "\n",
    "    return signals, labels\n",
    "\n",
    "def signal_transform_tensor_12(signals, N=0, max_len_signal=5000, sampling_rate=500):\n",
    "    \"\"\"Транформирует сигналы в тензор.\\n\n",
    "    N - номер отведения в соответствии с массивом:\\n\n",
    "    ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\"\"\"\n",
    "\n",
    "    # Ограничиваем максимальную длину до единого значения для использования в батче.\n",
    "    # Дописывать нули в конце для одной длины - сомнительная идея для LSTM.\n",
    "\n",
    "    results_reshape = []\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    for i in range(12):\n",
    "        # results_reshape.append(np.reshape([nk.ecg_clean(signal[i][0:max_len_signal], sampling_rate=sampling_rate) for signal in signals], (1, max_len_signal * len(signals))))\n",
    "        results_reshape.append(np.reshape([signal[i][0:max_len_signal] for signal in signals], (1, max_len_signal * len(signals))))\n",
    "\n",
    "    result_reshape = np.concatenate(results_reshape)\n",
    "\n",
    "    return torch.tensor(result_reshape, dtype=torch.float32).reshape((12, len(signals), max_len_signal)).permute((1,2,0))\n",
    "\n",
    "def signal_transform_tensor_12_scaled(signals, N=0, max_len_signal=5000, sampling_rate=500):\n",
    "    \"\"\"Транформирует сигналы в тензор.\\n\n",
    "    N - номер отведения в соответствии с массивом:\\n\n",
    "    ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\"\"\"\n",
    "\n",
    "    # Ограничиваем максимальную длину до единого значения для использования в батче.\n",
    "    # Дописывать нули в конце для одной длины - сомнительная идея для LSTM.\n",
    "\n",
    "    results_reshape = []\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    for i in range(12):\n",
    "        # results_reshape.append(np.reshape([nk.ecg_clean(signal[i][0:max_len_signal], sampling_rate=sampling_rate) for signal in signals], (1, max_len_signal * len(signals))))\n",
    "        s = [scaler.fit_transform(signal[i][0:max_len_signal].reshape(-1, 1)).reshape(max_len_signal) for signal in signals]\n",
    "        \n",
    "        results_reshape.append(np.reshape(s, (1, max_len_signal * len(signals))))\n",
    "\n",
    "    result_reshape = np.concatenate(results_reshape)\n",
    "\n",
    "    return torch.tensor(result_reshape, dtype=torch.float32).reshape((12, len(signals), max_len_signal)).permute((1,2,0))\n",
    "\n",
    "def label_transform_tensor(labels, all_diagnoses=False):\n",
    "    \"\"\"Транформирует лейблы в тензор.\\n\n",
    "    Сейчас только в режиме 'Норма-Не норма'.\"\"\"\n",
    "\n",
    "    # TODO: сделать разбиение лейблов на первичное и вторичное заключение врача\n",
    "\n",
    "    result_labels = []\n",
    "\n",
    "    if all_diagnoses:\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        # Норма - Не норма\n",
    "        for label in labels:\n",
    "            if label == '1':\n",
    "                result_labels.append(0)\n",
    "            else:\n",
    "                result_labels.append(1)\n",
    "\n",
    "    result_labels = torch.tensor(result_labels, dtype=torch.float32).reshape((len(result_labels), 1))\n",
    "\n",
    "    print(\"Label transformed to tensor successfully\\n\")\n",
    "\n",
    "    return result_labels\n",
    "\n",
    "def pipeline_2_model_iteration(N, save_weights_name, num_epochs=10, lr=0.001, momentum=0.9, weight_decay=0.0001, plot=False):\n",
    "    metadata_filepath = 'metadata.csv'\n",
    "    sample_freq = 500\n",
    "\n",
    "    max_len_signal = 5000\n",
    "\n",
    "    # Загружаем данные\n",
    "    signals, labels = load_data(metadata_filepath, sample_freq, N_end=N, only_health=True)\n",
    "\n",
    "    # Трансформируем данные для обучения\n",
    "    signals_12_transformed = signal_transform_tensor_12(signals, max_len_signal=max_len_signal)\n",
    "\n",
    "    labels_transformed = label_transform_tensor(labels)\n",
    "\n",
    "    # Разделение данных на вход (X) и метки (y)\n",
    "    X = signals_12_transformed.to(device)  # (batch_size, seq_len, input_size)\n",
    "    y = labels_transformed.to(device)\n",
    "\n",
    "    # Создание TensorDataset\n",
    "    dataset = TensorDataset(X, y)\n",
    "\n",
    "    # Разделение на обучающую и тестовую выборки\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # Создание DataLoader\n",
    "    batch_size = 7\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Параметры модели\n",
    "    seq_len = max_len_signal\n",
    "    input_size = 12\n",
    "    hidden_size = 64\n",
    "\n",
    "    model = RecurrentAutoencoder(seq_len, input_size, hidden_size)\n",
    "\n",
    "    print(\"Model initialized\\n\")\n",
    "\n",
    "    # # Определение функции потерь и оптимизатора\n",
    "    # criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "    # # optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    # criterion = nn.MSELoss()  # Среднеквадратичная ошибка\n",
    "\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.L1Loss(reduction='sum').to(device)\n",
    "\n",
    "    print(\"Model training...\\n\")\n",
    "    # Обучение модели\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "    \n",
    "        for batch_x, batch_y in progress_bar:\n",
    "            # return batch_x\n",
    "            optimizer.zero_grad()\n",
    "            # outputs = model(batch_x)\n",
    "            # loss = criterion(outputs, batch_y)\n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "\n",
    "            # Forward pass\n",
    "            # batch_x = batch_x[0]\n",
    "            batch_x = batch_x.to(device)\n",
    "            reconstructed_data = model(batch_x)\n",
    "\n",
    "            # Вычисление ошибки восстановления\n",
    "            loss = criterion(reconstructed_data, batch_x)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                \"Loss\": f\"{loss.item():.4f}\"\n",
    "            })\n",
    "            \n",
    "    torch.save(model.state_dict(), save_weights_name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "          Health    number:     75\n",
      "          Diseased  number:     0\n",
      "\n",
      "\n",
      "Label transformed to tensor successfully\n",
      "\n",
      "Model initialized\n",
      "\n",
      "Model training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/9 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 5000, 12])\n",
      "torch.Size([7, 5000, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/9 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 5000, 64])\n",
      "torch.Size([1, 7, 64])\n",
      "torch.Size([1, 7, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./weights/2encoder_12_2048_SGD_10_0.0001_0.9_0.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# gc.collect()\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m batch_x \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline_2_model_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_weights_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# torch.cuda.empty_cache()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[64], line 230\u001b[0m, in \u001b[0;36mpipeline_2_model_iteration\u001b[1;34m(N, save_weights_name, num_epochs, lr, momentum, weight_decay, plot)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# outputs = model(batch_x)\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# loss = criterion(outputs, batch_y)\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# batch_x = batch_x[0]\u001b[39;00m\n\u001b[0;32m    229\u001b[0m batch_x \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 230\u001b[0m reconstructed_data \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# Вычисление ошибки восстановления\u001b[39;00m\n\u001b[0;32m    233\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(reconstructed_data, batch_x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[61], line 79\u001b[0m, in \u001b[0;36mRecurrentAutoencoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     77\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 79\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[61], line 59\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 59\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim))\n\u001b[0;32m     62\u001b[0m     x, (hidden_n, cell_n) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn1(x)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor"
     ]
    }
   ],
   "source": [
    "# import gc\n",
    "\n",
    "save_path = './weights/2encoder_12_2048_SGD_10_0.0001_0.9_0.pth'\n",
    "\n",
    "# gc.collect()\n",
    "\n",
    "batch_x = pipeline_2_model_iteration(128, num_epochs=5, save_weights_name=save_path, lr=0.001, momentum=0.9, plot=True)\n",
    "\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5000, 12])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x_.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
